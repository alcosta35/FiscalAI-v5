# pinecone_setup.py
"""
Script para configurar e popular o Pinecone Vector Store com CFOPs
FiscalAI v5 - ValidaÃ§Ã£o SemÃ¢ntica de CFOP
"""
import pandas as pd
import os
from typing import List, Dict
from pinecone import Pinecone, ServerlessSpec
from openai import OpenAI
import time

class PineconeCFOPSetup:
    """Classe para configurar o Pinecone Vector Store com dados de CFOP"""
    
    def __init__(
        self, 
        cfop_csv_path: str,
        pinecone_api_key: str = None,
        openai_api_key: str = None,
        index_name: str = "fiscalai-cfop"
    ):
        """
        Inicializa o setup do Pinecone
        
        Args:
            cfop_csv_path: Caminho para o arquivo CFOP.csv
            pinecone_api_key: Chave API do Pinecone (ou usar variÃ¡vel de ambiente)
            openai_api_key: Chave API da OpenAI (ou usar variÃ¡vel de ambiente)
            index_name: Nome do Ã­ndice no Pinecone
        """
        self.cfop_csv_path = cfop_csv_path
        self.index_name = index_name
        
        # Configurar APIs
        self.pinecone_api_key = pinecone_api_key or os.getenv("PINECONE_API_KEY")
        self.openai_api_key = openai_api_key or os.getenv("OPENAI_API_KEY")
        
        if not self.pinecone_api_key:
            raise ValueError("PINECONE_API_KEY nÃ£o configurada")
        if not self.openai_api_key:
            raise ValueError("OPENAI_API_KEY nÃ£o configurada")
        
        # Inicializar clientes
        self.pc = Pinecone(api_key=self.pinecone_api_key)
        self.openai_client = OpenAI(api_key=self.openai_api_key)
        
        # ConfiguraÃ§Ã£o de embeddings
        self.embedding_model = "text-embedding-3-small"
        self.embedding_dimension = 1536
        
        print("âœ… Clientes Pinecone e OpenAI inicializados")
    
    def load_cfop_data(self) -> pd.DataFrame:
        """Carrega e processa dados do CFOP.csv"""
        print(f"\nğŸ“‚ Carregando {self.cfop_csv_path}...")
        
        df = pd.read_csv(self.cfop_csv_path, encoding='utf-8-sig')
        
        # Limpar dados
        df = df.dropna(subset=['CFOP', 'APLICAÃ‡ÃƒO'])
        df['CFOP'] = df['CFOP'].astype(str).str.strip()
        df['DESCRIÃ‡ÃƒO'] = df['DESCRIÃ‡ÃƒO'].fillna('').astype(str)
        df['APLICAÃ‡ÃƒO'] = df['APLICAÃ‡ÃƒO'].astype(str)
        
        # Filtrar apenas CFOPs vÃ¡lidos (numÃ©ricos)
        df = df[df['CFOP'].str.replace('.', '').str.isdigit()]
        
        print(f"âœ… {len(df)} CFOPs carregados")
        return df
    
    def create_embedding_text(self, row: pd.Series) -> str:
        """
        Cria texto otimizado para embedding a partir da linha do CFOP
        
        Combina APLICAÃ‡ÃƒO + DESCRIÃ‡ÃƒO para contexto rico
        """
        cfop = row['CFOP']
        descricao = row['DESCRIÃ‡ÃƒO']
        aplicacao = row['APLICAÃ‡ÃƒO']
        
        # Texto para embedding (rico em contexto)
        text = f"""
        CFOP: {cfop}
        DescriÃ§Ã£o: {descricao}
        
        AplicaÃ§Ã£o e Contexto:
        {aplicacao}
        """.strip()
        
        return text
    
    def generate_embeddings(self, texts: List[str], batch_size: int = 100) -> List[List[float]]:
        """
        Gera embeddings usando OpenAI API em lotes
        
        Args:
            texts: Lista de textos para gerar embeddings
            batch_size: Tamanho do lote
        """
        print(f"\nğŸ§  Gerando embeddings para {len(texts)} textos...")
        
        all_embeddings = []
        
        for i in range(0, len(texts), batch_size):
            batch = texts[i:i + batch_size]
            
            try:
                response = self.openai_client.embeddings.create(
                    input=batch,
                    model=self.embedding_model
                )
                
                batch_embeddings = [item.embedding for item in response.data]
                all_embeddings.extend(batch_embeddings)
                
                print(f"  âœ“ Processados {min(i + batch_size, len(texts))}/{len(texts)} textos")
                
                # Rate limiting
                time.sleep(0.5)
                
            except Exception as e:
                print(f"  âŒ Erro no lote {i}: {e}")
                raise
        
        print("âœ… Embeddings gerados com sucesso")
        return all_embeddings
    
    def create_index(self, dimension: int = 1536):
        """Cria Ã­ndice no Pinecone se nÃ£o existir"""
        print(f"\nğŸ”§ Configurando Ã­ndice '{self.index_name}'...")
        
        # Verificar se Ã­ndice jÃ¡ existe
        existing_indexes = [index.name for index in self.pc.list_indexes()]
        
        if self.index_name in existing_indexes:
            print(f"âš ï¸  Ãndice '{self.index_name}' jÃ¡ existe")
            
            # Perguntar se quer deletar
            delete = input("Deseja deletar e recriar? (s/n): ").lower()
            if delete == 's':
                self.pc.delete_index(self.index_name)
                print("ğŸ—‘ï¸  Ãndice deletado")
                time.sleep(5)  # Aguardar propagaÃ§Ã£o
            else:
                print("â„¹ï¸  Usando Ã­ndice existente")
                return
        
        # Criar novo Ã­ndice
        self.pc.create_index(
            name=self.index_name,
            dimension=dimension,
            metric="cosine",
            spec=ServerlessSpec(
                cloud="aws",
                region="us-east-1"
            )
        )
        
        print(f"âœ… Ãndice '{self.index_name}' criado")
        
        # Aguardar Ã­ndice ficar pronto
        print("â³ Aguardando Ã­ndice ficar pronto...")
        time.sleep(10)
    
    def upsert_vectors(self, df: pd.DataFrame, embeddings: List[List[float]]):
        """Faz upload dos vetores para o Pinecone"""
        print(f"\nğŸ“¤ Fazendo upload de {len(embeddings)} vetores...")
        
        # Conectar ao Ã­ndice
        index = self.pc.Index(self.index_name)
        
        # Preparar dados para upsert
        vectors = []
        for idx, (_, row) in enumerate(df.iterrows()):
            vector_data = {
                "id": f"cfop_{row['CFOP']}_{idx}",
                "values": embeddings[idx],
                "metadata": {
                    "cfop": row['CFOP'],
                    "descricao": row['DESCRIÃ‡ÃƒO'][:500],  # Limitar tamanho
                    "aplicacao": row['APLICAÃ‡ÃƒO'][:1000]  # Limitar tamanho
                }
            }
            vectors.append(vector_data)
        
        # Upsert em lotes
        batch_size = 100
        for i in range(0, len(vectors), batch_size):
            batch = vectors[i:i + batch_size]
            index.upsert(vectors=batch)
            print(f"  âœ“ Upload {min(i + batch_size, len(vectors))}/{len(vectors)}")
            time.sleep(0.5)
        
        print("âœ… Upload concluÃ­do")
        
        # Verificar estatÃ­sticas
        stats = index.describe_index_stats()
        print(f"\nğŸ“Š EstatÃ­sticas do Ã­ndice:")
        print(f"   Total de vetores: {stats['total_vector_count']}")
    
    def setup_complete(self) -> Dict:
        """
        Executa o setup completo:
        1. Carrega CFOPs
        2. Gera embeddings
        3. Cria Ã­ndice
        4. Faz upload dos vetores
        """
        print("\n" + "="*70)
        print("ğŸš€ FISCALAI v5 - SETUP PINECONE VECTOR STORE")
        print("="*70)
        
        # 1. Carregar dados
        df = self.load_cfop_data()
        
        # 2. Criar textos para embedding
        print("\nğŸ“ Preparando textos para embedding...")
        texts = [self.create_embedding_text(row) for _, row in df.iterrows()]
        print(f"âœ… {len(texts)} textos preparados")
        
        # 3. Gerar embeddings
        embeddings = self.generate_embeddings(texts)
        
        # 4. Criar Ã­ndice
        self.create_index(dimension=self.embedding_dimension)
        
        # 5. Upload vetores
        self.upsert_vectors(df, embeddings)
        
        print("\n" + "="*70)
        print("âœ… SETUP CONCLUÃDO COM SUCESSO!")
        print("="*70)
        
        return {
            "status": "success",
            "index_name": self.index_name,
            "total_cfops": len(df),
            "embedding_dimension": self.embedding_dimension,
            "embedding_model": self.embedding_model
        }


def main():
    """FunÃ§Ã£o principal para executar o setup"""
    import sys
    
    # Configurar paths
    if len(sys.argv) > 1:
        cfop_csv_path = sys.argv[1]
    else:
        # Default para Colab
        cfop_csv_path = "/content/FiscalAI-v4/data/CFOP.csv"
    
    # Verificar se arquivo existe
    if not os.path.exists(cfop_csv_path):
        print(f"âŒ Arquivo nÃ£o encontrado: {cfop_csv_path}")
        print("\nğŸ’¡ Use: python pinecone_setup.py <caminho_do_cfop.csv>")
        return
    
    # Executar setup
    setup = PineconeCFOPSetup(cfop_csv_path=cfop_csv_path)
    result = setup.setup_complete()
    
    print("\nğŸ“‹ Resultado:")
    for key, value in result.items():
        print(f"   {key}: {value}")


if __name__ == "__main__":
    main()
