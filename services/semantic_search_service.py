# services/semantic_search_service.py
"""
Servi√ßo de Busca Sem√¢ntica para CFOP usando Pinecone e OpenAI Embeddings
"""
import os
from typing import List, Dict, Optional, Tuple
from pinecone import Pinecone, ServerlessSpec
from openai import OpenAI
import pandas as pd
from dotenv import load_dotenv

load_dotenv()


class CFOPSemanticSearchService:
    """Servi√ßo de busca sem√¢ntica de CFOP usando embeddings"""
    
    def __init__(self, index_name: str = "cfop-fiscal"):
        """
        Inicializa o servi√ßo de busca sem√¢ntica
        
        Args:
            index_name: Nome do √≠ndice Pinecone
        """
        print("\n" + "="*70)
        print("üîç INICIALIZANDO SERVI√áO DE BUSCA SEM√ÇNTICA")
        print("="*70)
        
        # Configurar API keys
        self.openai_api_key = os.getenv("OPENAI_API_KEY")
        self.pinecone_api_key = os.getenv("PINECONE_API_KEY")
        
        if not self.openai_api_key:
            raise ValueError("‚ùå OPENAI_API_KEY n√£o encontrada!")
        if not self.pinecone_api_key:
            raise ValueError("‚ùå PINECONE_API_KEY n√£o encontrada!")
        
        print(f"üîë OpenAI API Key: {self.openai_api_key[:8]}...{self.openai_api_key[-4:]}")
        print(f"üîë Pinecone API Key: {self.pinecone_api_key[:8]}...{self.pinecone_api_key[-4:]}")
        
        # Inicializar clientes
        self.openai_client = OpenAI(api_key=self.openai_api_key)
        self.pc = Pinecone(api_key=self.pinecone_api_key)
        
        self.index_name = index_name
        self.embedding_model = "text-embedding-3-small"
        self.embedding_dimension = 1536  # Dimens√£o do modelo text-embedding-3-small
        
        # Inicializar ou conectar ao √≠ndice
        self._setup_index()
        
        print("="*70)
        print("‚úÖ SERVI√áO DE BUSCA SEM√ÇNTICA INICIALIZADO!")
        print("="*70 + "\n")
    
    def _setup_index(self):
        """Configura ou conecta ao √≠ndice Pinecone"""
        print(f"üìä Configurando √≠ndice: {self.index_name}")
        
        # Listar √≠ndices existentes
        existing_indexes = [index.name for index in self.pc.list_indexes()]
        
        if self.index_name not in existing_indexes:
            print(f"   ‚ö†Ô∏è √çndice n√£o existe. Criando novo √≠ndice...")
            
            self.pc.create_index(
                name=self.index_name,
                dimension=self.embedding_dimension,
                metric="cosine",
                spec=ServerlessSpec(
                    cloud="aws",
                    region="us-east-1"
                )
            )
            print(f"   ‚úÖ √çndice '{self.index_name}' criado com sucesso!")
        else:
            print(f"   ‚úÖ Conectado ao √≠ndice existente: {self.index_name}")
        
        # Conectar ao √≠ndice
        self.index = self.pc.Index(self.index_name)
        
        # Mostrar estat√≠sticas
        stats = self.index.describe_index_stats()
        print(f"   üìà Vetores no √≠ndice: {stats.total_vector_count}")
    
    def generate_embedding(self, text: str) -> List[float]:
        """
        Gera embedding para um texto usando OpenAI
        
        Args:
            text: Texto para gerar embedding
            
        Returns:
            Lista de floats representando o embedding
        """
        try:
            response = self.openai_client.embeddings.create(
                input=text,
                model=self.embedding_model
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"‚ùå Erro ao gerar embedding: {e}")
            raise
    
    def populate_index_from_csv(self, cfop_csv_path: str, batch_size: int = 100):
        """
        Popula o √≠ndice Pinecone com embeddings dos CFOPs do CSV
        
        Args:
            cfop_csv_path: Caminho para o arquivo CSV de CFOPs
            batch_size: Tamanho do batch para upload
        """
        print("\n" + "="*70)
        print("üì• POPULANDO √çNDICE PINECONE COM CFOPs")
        print("="*70)
        
        # Carregar CSV
        print(f"üìÇ Carregando: {cfop_csv_path}")
        df_cfop = pd.read_csv(cfop_csv_path)
        print(f"   ‚úÖ {len(df_cfop)} c√≥digos CFOP carregados")
        
        # Filtrar apenas linhas com CFOP v√°lido
        df_cfop_validos = df_cfop[df_cfop['CFOP'].notna()].copy()
        print(f"   ‚úÖ {len(df_cfop_validos)} CFOPs v√°lidos para indexa√ß√£o")
        
        vectors_to_upsert = []
        total_processed = 0
        
        for idx, row in df_cfop_validos.iterrows():
            try:
                cfop_code = str(row['CFOP']).strip()
                aplicacao = str(row.get('APLICA√á√ÉO', '')).strip()
                descricao = str(row.get('DESCRI√á√ÉO', '')).strip()
                
                # Pular linhas sem aplica√ß√£o ou descri√ß√£o
                if not aplicacao or aplicacao == 'nan' or len(aplicacao) < 10:
                    continue
                
                # Criar texto para embedding (concatenar aplica√ß√£o e descri√ß√£o)
                text_for_embedding = f"{aplicacao}\n\n{descricao}"
                
                # Gerar embedding
                embedding = self.generate_embedding(text_for_embedding)
                
                # Preparar metadata
                metadata = {
                    "cfop": cfop_code,
                    "aplicacao": aplicacao[:1000],  # Limitar tamanho
                    "descricao": descricao[:1000],
                    "texto_completo": text_for_embedding[:2000]
                }
                
                # Adicionar ao batch
                vectors_to_upsert.append({
                    "id": f"cfop_{cfop_code.replace('.', '_')}",
                    "values": embedding,
                    "metadata": metadata
                })
                
                total_processed += 1
                
                # Upload em batches
                if len(vectors_to_upsert) >= batch_size:
                    self.index.upsert(vectors=vectors_to_upsert)
                    print(f"   ‚úÖ Batch de {len(vectors_to_upsert)} vetores enviado ({total_processed}/{len(df_cfop_validos)})")
                    vectors_to_upsert = []
                
            except Exception as e:
                print(f"   ‚ö†Ô∏è Erro ao processar CFOP {cfop_code}: {e}")
                continue
        
        # Upload do √∫ltimo batch
        if vectors_to_upsert:
            self.index.upsert(vectors=vectors_to_upsert)
            print(f"   ‚úÖ √öltimo batch de {len(vectors_to_upsert)} vetores enviado")
        
        print("="*70)
        print(f"‚úÖ INDEXA√á√ÉO CONCLU√çDA! Total: {total_processed} CFOPs")
        print("="*70 + "\n")
    
    def search_cfop(
        self, 
        query_text: str, 
        top_k: int = 5,
        filter_dict: Optional[Dict] = None
    ) -> List[Dict]:
        """
        Busca CFOPs semanticamente similares √† query
        
        Args:
            query_text: Texto descrevendo a opera√ß√£o fiscal
            top_k: N√∫mero de resultados a retornar
            filter_dict: Filtros opcionais para metadata
            
        Returns:
            Lista de dicion√°rios com CFOP e score de similaridade
        """
        try:
            # Gerar embedding da query
            query_embedding = self.generate_embedding(query_text)
            
            # Buscar no Pinecone
            results = self.index.query(
                vector=query_embedding,
                top_k=top_k,
                include_metadata=True,
                filter=filter_dict
            )
            
            # Formatar resultados
            formatted_results = []
            for match in results.matches:
                formatted_results.append({
                    "cfop": match.metadata.get("cfop"),
                    "score": match.score,
                    "aplicacao": match.metadata.get("aplicacao"),
                    "descricao": match.metadata.get("descricao")
                })
            
            return formatted_results
            
        except Exception as e:
            print(f"‚ùå Erro na busca: {e}")
            raise
    
    def infer_cfop_for_item(
        self,
        natureza_operacao: str,
        uf_emitente: str,
        uf_destinatario: str,
        descricao_produto: str,
        consumidor_final: str,
        indicador_ie: str = "1"
    ) -> Tuple[str, float, str]:
        """
        Infere o CFOP mais adequado para um item baseado em seus atributos
        
        Args:
            natureza_operacao: Natureza da opera√ß√£o (ex: "VENDA", "DEVOLU√á√ÉO")
            uf_emitente: UF do emitente
            uf_destinatario: UF do destinat√°rio
            descricao_produto: Descri√ß√£o do produto/servi√ßo
            consumidor_final: Se √© consumidor final ("0" ou "1")
            indicador_ie: Indicador de IE do destinat√°rio
            
        Returns:
            Tupla (cfop_sugerido, score_confianca, explicacao)
        """
        print("\n" + "="*70)
        print("üîç INFERINDO CFOP VIA BUSCA SEM√ÇNTICA")
        print("="*70)
        
        # Construir query sem√¢ntica
        query_parts = []
        
        # Adicionar natureza da opera√ß√£o
        query_parts.append(f"Opera√ß√£o: {natureza_operacao}")
        
        # Adicionar √¢mbito geogr√°fico
        if uf_emitente == uf_destinatario:
            query_parts.append("Opera√ß√£o interna (dentro do mesmo estado)")
        else:
            query_parts.append(f"Opera√ß√£o interestadual (de {uf_emitente} para {uf_destinatario})")
        
        # Adicionar informa√ß√µes do produto
        if descricao_produto and descricao_produto != 'nan':
            query_parts.append(f"Produto: {descricao_produto}")
        
        # Adicionar se √© consumidor final
        if consumidor_final == "1":
            query_parts.append("Destinat√°rio √© consumidor final")
        else:
            query_parts.append("Destinat√°rio n√£o √© consumidor final")
        
        # Adicionar informa√ß√£o de IE
        if indicador_ie == "1":
            query_parts.append("Destinat√°rio √© contribuinte do ICMS")
        elif indicador_ie == "9":
            query_parts.append("Destinat√°rio n√£o √© contribuinte do ICMS")
        
        query_text = ". ".join(query_parts)
        
        print(f"üìù Query constru√≠da:\n{query_text}")
        print("-"*70)
        
        # Buscar CFOPs similares
        results = self.search_cfop(query_text, top_k=3)
        
        if not results:
            print("‚ùå Nenhum resultado encontrado")
            return ("INDEFINIDO", 0.0, "Nenhum CFOP correspondente encontrado")
        
        # Melhor match
        best_match = results[0]
        cfop_sugerido = best_match["cfop"]
        score = best_match["score"]
        
        # Criar explica√ß√£o
        explicacao = f"""
üéØ CFOP SUGERIDO: {cfop_sugerido} (Confian√ßa: {score:.2%})

üìã APLICA√á√ÉO:
{best_match['aplicacao'][:300]}...

üí° ALTERNATIVAS CONSIDERADAS:
"""
        for i, result in enumerate(results[1:], 1):
            explicacao += f"\n{i}. CFOP {result['cfop']} (Score: {result['score']:.2%})"
        
        print(f"\n‚úÖ CFOP sugerido: {cfop_sugerido} (score: {score:.2%})")
        print("="*70 + "\n")
        
        return (cfop_sugerido, score, explicacao)
    
    def clear_index(self):
        """Limpa todos os vetores do √≠ndice"""
        print(f"‚ö†Ô∏è Limpando √≠ndice {self.index_name}...")
        self.index.delete(delete_all=True)
        print("‚úÖ √çndice limpo!")
    
    def get_index_stats(self) -> Dict:
        """Retorna estat√≠sticas do √≠ndice"""
        stats = self.index.describe_index_stats()
        return {
            "total_vectors": stats.total_vector_count,
            "dimension": self.embedding_dimension,
            "index_name": self.index_name
        }
